#!/usr/bin/env python3
#
# Seafile Administration Web-To-CLI-Wrapper
# Copyright (C) 2013-2019 Henri Wahl <h.wahl@ifw-dresden.de>
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA


import bs4
import configparser
import getopt
import json
import os.path
import queue
import psutil
import requests
import shlex
import subprocess
import sys
import threading
import time
import traceback
import urllib3

USAGE = """
seafadm [option...] [command] [argument]

Valid options are:

    -c, --config      location for config file for URL, username and password
    -U, --url         URL of Seafile server, e.g. https://seafile.local
    -u, --username    username of Seafile admin account
    -p, --password    password for givern username
    -F, --force       disable confirmation for delete and quota command

Valid commands are:

    show              show informations about users, libraries, groups and links
    add               add users
    delete            delete users, libraries, groups and links
    quota             set quota for single users and whole domains
    search            search for users, groups and links
    report            generate report per user to be sent by mail
    check             check for invalid links
    clean             check for invalid links and delete them

Arguments for show command:

    users             show all users, their ID, creation date and quota as list
    user <username>   show extra details about <username>, its libraries, shares and groups
    libs              show all libraries, their ID and owners as list
    groups            show all groups, their ID, owner, creation date and members as list
    group <group>     show details about single <group>
    links             show links, their ID, creation date and URL as list ordered by owner
    all               show extra details about all users

Arguments for add command:

    user <email> <password>     add user <email> with password <password>


Arguments for delete command:

    user <username>   delete <username>
    lib <repo-id>     delete library with ID <repo-id>
    link <link>       delete link <link> identified by URL or ID
    group <group>     delete group identified by group name <group>

Arguments for quota command:

    user <username> <quota>        set quota for <username> to <quota> MB
    domain <domain> <quota>        set quota for users from <domain> to <quota> MB
    domain not <domain> <quota>    set quota for users NOT from <domain> to <quota> MB
    domain min <domain> <quota>    set quota for users from <domain> to a minimum of
                                   <quota> MB

Arguments for search command:

    user <string>    search in users for <string>
    group <string>    search in groups for <string>
    link <string>     search in links for <string>

Arguments for report command:

    user <username>   generate report for user <username>, to be sent by mail for example

Arguments for check command:

    links             check validity of links and display them ordered by validity

Arguments for clean command:

    links                       check validity of links and delete them if invalid
    garbage [threads] [path]    run seaf_gc threads for faster garbage collection
                                [threads] defaults to 10 and [path] to /opt/seafile

EXAMPLES:

Showing all users, their libraries, groups and memberships:

    seafadm -c ./seafadm.conf show all

Showing users as list:

    seafadm -c ./seafadm.conf show users

Showing details about one single user:

    seafadm -c ./seafadm.conf show user joe@example.com

Adding an user:

    seafadm -c ./seafadm.conf add user joe@example.com bar1234

Deleting an user:

    seafadm -c ./seafadm.conf delete user joe@example.com

Deleting a library:

    seafadm -c ./seafadm.conf delete lib 1c17cddc-2864-407c-8fcf-6a325964d00b

Setting quota to 10240 MB for an user:

    seafadm -c ./seafadm.conf quota user joe@example.com 10240

Setting quota to 4096 MB for users of domain example.com:

    seafadm -c ./seafadm.conf quota domain example.com 4096

Setting quota to a minimum of 20480 MB for all users of domain example.com:

    seafadm -c ./seafadm.conf quota domain min example.com 20480

Setting quota to 1 MB for all users NOT in domain example.com:

    seafadm -c ./seafadm.conf quota domain not example.com 1

Search for user joe in users:

    seafadm -c ./seafadm.conf search user joe

Generate report for user joe@example.com

    seafadm -c ./seafadm.conf report user joe@example.com

Check validity of links

    seafadm -c ./seafadm.conf check links

Delete invalid links

    seafadm -c ./seafadm.conf clean links
"""

# suppress SSL warnings - does not work on CentOS 6, so there is a condition
if 'packages' in dir(requests):
    if 'urllib3' in dir(requests.packages):
        requests.packages.urllib3.disable_warnings()

# default disable https warnings
urllib3.disable_warnings()

# less UTF-8-sensible print replacement
# might not be necessary with Python 3
# out = codecs.getwriter('utf-8')(sys.stdout)

# default config parameters
CONFIG_FILE = SEAFILE_URL = SEAFILE_USERNAME = SEAFILE_PASSWORD = SEAFILE_ADMIN = SEAFILE_START = SEAFILE_STOP = ''
# items to be shown per page to avoid pagination - 100000 should be enough
PER_PAGE = 100000
# user API JSON return dictionaries are named differently, needed to read them
USER_API_KEYS = {'users': 'data', 'ldap-users': 'ldap_user_list'}
# no forcing as default
FORCE = False

queue_garbage = queue.Queue(maxsize=0)
number_of_threads = 10
number_of_libraries = 0

SEAFILE_DIR = '/opt/seafile'
SEAF_GC = SEAFILE_DIR + '/seafile-server-latest/seafile/bin/seafserv-gc'


def error_exit(message='An error occurred.', status=1):
    """
    exit with given error message
    allow prefix, especially for spitting out section of configuration errors
    """
    print('\n' + message + '\n')
    sys.exit(status)


class User:
    """
    store information about a user
    """
    mail = creation = quota = used_space = libs = groups = links = id = shares = None

    def __init__(self, **kwds):
        # fill properties with given values
        for k in kwds:
            self.__dict__[k] = kwds[k]

    def print_info(self):
        """
        pretty prints user details
        """
        print('User:\t%s' % self.mail)
        print('ID:\t%s' % self.id)
        print('Quota:\t%s' % ('%s/%s MB' % (self.used_space, self.quota)))
        print('Date:\t%s' % self.creation)
        if len(self.libs) > 0:
            category = 'Libs:'
            for l in self.libs:
                print('%s\t%s' % (category, ' | '.join((l.id, l.name))))
                category = ''
        if len(self.groups) > 0:
            category = 'Groups:'
            for g in self.groups:
                if g.owner == self.mail:
                    print('%s\t%s %s' % (category, g.name, '(Owner)'))
                else:
                    print('%s\t%s' % (category, g.name))
                category = ''
        if len(self.links) > 0:
            category = 'Links:'
            for l in self.links:
                print('%s\t%s' % (category, ' | '.join((l.URL, l.Creation, l.name))))
                category = ''
        if len(self.shares) > 0:
            category = 'Shares:'
            for s in self.shares:
                if s.type == 'user':
                    print('%s\t%s by user %s' % (category, s.name, s.owner))
                else:
                    print('%s\t%s by group %s' % (category, s.name, s.group))
                category = ''

    def print_report(self):
        """
        pretty prints user details in HTML
        """
        print('<html><head></head><body>')
        print('<h2>Seafile report for %s</h2>' % self.mail)
        print('<p>Registered since: %s</p>' % self.creation)
        print('<p>Used space: %s</p>' % ('%s MB of %s MB\n' % (self.used_space, self.quota)))
        if len(self.libs) > 0:
            print('<h3>Libraries:</h3>')
            for l in self.libs:
                print('%s<br>' % l.name)
            print('<p>Manage your libraries at <a href=%s/#my-libs/>%s/#my-libs/</a></p>' % (SEAFILE_URL, SEAFILE_URL))
        if len(self.groups) > 0:
            print('<h3>Groups:</h3>')
            for g in self.groups:
                if g.owner == self.mail:
                    print('%s %s<br>' % (g.name, '(Owner)'))
                else:
                    print('%s<br>' % g.name)
            print('<p>Manage your groups at <a href=%s/#groups/>%s/#groups/</a></p>' % (SEAFILE_URL, SEAFILE_URL))
        if len(self.links) > 0:
            print('<h3>Links you share:</h3>')
            for l in self.links:
                print('<a href=%s>%s</a> %s<br>' % (l.URL, l.URL, l.name))
            print()
            print('<p>Manage your links at <a href=%s/#share-admin-share-links/>%s/#share-admin-share-links/</a></p>' %
                  (SEAFILE_URL, SEAFILE_URL))
        if len(self.shares) > 0:
            print('<h3>Libraries shared with you:</h3>')
            for s in self.shares:
                if s.type == 'user':
                    print('%s by user %s<br>' % (s.name, s.owner))
                else:
                    print('%s by group %s<br>' % (s.name, s.group))
            print()
            print('<p>Manage your shares at <a href=%s/#share-admin-libs/>%s/#share-admin-libs/</a></p>' %
                  (SEAFILE_URL, SEAFILE_URL))
        if SEAFILE_ADMIN != '':
            print('<p>If you want to delete your Seafile account at %s please contact <a href=mailto:%s>%s</a>.</p>' %
                  (SEAFILE_URL, SEAFILE_ADMIN, SEAFILE_ADMIN))
        print('</body></html>')

    def collect_info(self, libs, links, groups):
        """
        sort user information
        """
        self.libs = list()
        for l in libs.values():
            if self.mail == l.owner:
                self.libs.append(l)
        self.libs.sort(key=lambda x: x.name)
        self.groups = list()
        for g in groups.values():
            if self.mail in g.members:
                self.groups.append(g)
        self.groups.sort(key=lambda x: x.name)
        self.links = list()
        for l in links.values():
            if self.mail in l.owner:
                self.links.append(l)
        self.links.sort(key=lambda x: x.name)
        # get shares given for user
        self.shares = self.get_shares()
        for g in self.groups:
            for s in g.get_shares():
                self.shares.append(s)
        return True

    def get_shares(self):
        """
        get shares a user gets from other users
        """
        shares = list()
        for s in get_data('/useradmin/info/%s/' % self.mail, section='Shared'):
            share = Share(name=s[1], owner=s[2], type='user')
            shares.append(share)
        return shares


class Library:
    """
    a single library
    """
    name = id = owner = None

    def __init__(self, **kwds):
        # fill properties with given values
        for k in kwds:
            self.__dict__[k] = kwds[k]


class Link:
    """
    publicly available link
    """
    name = owner = creation = count = type = url = id = validity = None

    def __init__(self, **kwds):
        # fill properties with given values
        for k in kwds:
            self.__dict__[k] = kwds[k]

    def print_info(self):
        """
        pretty prints link details
        """
        print('Link:\t%s' % self.name)
        print('ID:\t%s' % self.id)
        print('Date:\t%s' % self.creation)
        print('Owner:\t%s' % self.owner)
        print('Type:\t%s' % self.type)
        print('URL:\t%s' % self.url)

    def is_valid(self):
        """
        check validity of URL
        """
        self.validity = True
        try:
            # add '/' to avoid HTTP status codes 301 and thus double number of requests
            if not self.url.endswith('/'):
                self.url += '/'
            soup = get_soup(self.url)
            # text-panel contains error message - if no error then no text-panel div
            for e in soup.find_all(attrs={'class': 'text-panel'}):
                # if something found link is invalid
                self.validity = False
        except requests.exceptions.HTTPError:
            self.validity = False
        return self.validity


class Group:
    """
    group and its members
    """
    name = id = owner = creation = members = None

    def __init__(self, **kwds):
        # fill properties with given values
        for k in kwds:
            self.__dict__[k] = kwds[k]

    def print_info(self):
        """
        pretty prints group details
        """
        print('Group:\t%s' % self.name)
        print('ID:\t%s' % self.id)
        print('Date:\t%s' % self.creation)
        print('Owner:\t%s' % self.owner)
        if len(self.members) > 0:
            category = 'Member:'
            for l in self.members:
                print('%s\t%s' % (category, l))
                category = ''

    def get_shares(self):
        """
        get shares a group gets from users
        """
        shares = list()
        for s in get_data('/group/%s/' % self.id, section='grp-repos'):
            share = Share(name=s[1], owner=s[2], type='group', group=self.name)
            shares.append(share)
        return shares


class Share:
    """
    a single share
    """
    name = owner = type = group = None

    def __init__(self, **kwds):
        # fill properties with given values
        for k in kwds:
            self.__dict__[k] = kwds[k]


class WorkerGarbage(threading.Thread):
    """
    Actual worker for garbage cleaning
    """

    def __init__(self, queue_garbage):
        threading.Thread.__init__(self, name='GarbageCollector')
        self.daemon = True
        self.queue_garbage = queue_garbage

    def run(self):
        """
        As long as there are libraries in queue (or number of remaining libraries is > 0) take libraries out of queue
        and process them
        :return:
        """
        # needed global values
        global number_of_libraries, SEAFILE_DIR

        while number_of_libraries > 0:
            try:
                # get library from queue
                library = self.queue_garbage.get()
                # prepare arguments and environment
                args = shlex.split('{0} -c {1}/ccnet -d {1}/seafile-data -F {1}/conf {2}'.format(SEAF_GC,
                                                                                                 SEAFILE_DIR, library))
                env = {'LD_LIBRARY_PATH': '{0}/seafile-server-latest/seafile/lib:'
                                          '{0}/seafile-server-latest/seafile/lib64'.format(SEAFILE_DIR)}

                print('Processing library:', library)
                process = subprocess.Popen(args, env=env, cwd=SEAFILE_DIR)
                (output, error) = process.communicate()
                status = process.wait()
                print('Processed library:', library)
                print('Thread ident:', self.ident)
                print('Output:', output)
                print('Error:', error)
                queue_garbage.task_done()

            except:
                traceback.print_exc(file=sys.stdout)
                sys.stdout.flush()

            number_of_libraries -= 1
            print('Remaining libraries:', number_of_libraries)


def get_url(url, data=None):
    """
    shortcut for URL request
    """
    if data is not None:
        data['csrfmiddlewaretoken'] = csrf_token
        data['submit'] = 'Submit'
        response = session.post(url, data)
    else:
        response = session.get(url)

    return response.text


def get_ajax(url, data=None, referer=None):
    """
    shortcut for Ajax request
    """
    headers = dict(list(session.headers.copy().items()))
    headers.update({'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
                    'Accept': 'application/json, text/javascript, */*; q=0.01',
                    'X-Requested-With': 'XMLHttpRequest'})
    if referer is not None:
        headers.update({'Referer': referer})
    if not url.startswith('http'):
        url = '{0}{1}'.format(SEAFILE_URL, url)
    if data is None:
        response = session.get(url, headers=headers)
    else:
        response = session.post(url, data=data, headers=headers)

    return response.text


def get_soup(url, data=None):
    """
    get HTML content as BeautifulSoup object
    """
    url_data = get_url(url, data)
    try:
        soup = bs4.BeautifulSoup(url_data, features='lxml')
    except:
        soup = bs4.BeautifulSoup(url_data, features='html.parser')

    return soup


def get_data(data_url, mode='simple', section=''):
    """
    get data of given URL, e.g. users, needing desired section of page
    """
    rows = list()
    table = None
    # sub-url as data-url gets anti-pagination-page-request added
    soup = get_soup(SEAFILE_URL + data_url + '?per_page=%s' % PER_PAGE)
    # sections are headed by h3 headers or li list items and thus identifyable
    h3s = soup.find_all('h3')
    for h3 in h3s:
        if h3.string == section:
            table = h3.find_next_sibling('table')
            break
    # some pages show information in tables inside of certain divs which should be named by id
    if table is None:
        div = soup.find(id=section)
        if div is not None:
            try:
                table = div.find_all('table')[0]
            except:
                pass
    if table is not None:
        for tr in table:
            # there are some empty passages in HTML which have no .find_all() method
            if isinstance(tr, bs4.element.Tag):
                columns = list()
                for td in tr.find_all('td'):
                    if td.string is not None:
                        if mode == 'simple':
                            data = td.string.replace('\n', '').strip()
                        elif mode == 'verbose':
                            string = td.string.replace('\n', '').strip()
                            soup = td
                            data = [string, soup]
                    else:
                        data = td
                    columns.append(data)
                # only add colums that contains any data
                if not len(columns) == 0:
                    rows.append(columns)
    return rows


def get_users():
    """
    retrieve information about all libraries
    """
    users = dict()
    # returned lsit of users comes in different dictionaries in JSON
    for user_db in USER_API_KEYS:
        result = json.loads(get_ajax(f'/api/v2.1/admin/{user_db}'))
        if result.get(USER_API_KEYS[user_db]):
            for item in result[USER_API_KEYS[user_db]]:
                # LDAP users do not have name property - just use mail address instead
                user = User(name=item.get('name', item['email']),
                            id=item['email'],
                            mail=item['email'],
                            creation=item['create_time'],
                            used_space=int(item['quota_usage']/1000000),
                            quota=int(item['quota_total']/1000000)
                            )
                users[user.id] = user
    return users

def get_libaries():
    """
    retrieve information about all libraries
    """
    libraries = dict()
    result = json.loads(get_ajax('/api/v2.1/admin/libraries?per_page=999999'))
    for lib in result['repos']:
        library = Library(name=lib['name'],
                          id=lib['id'],
                          owner=lib['owner'])
        libraries[library.id] = library
    return libraries


def get_links():
    """
    get all publicly shared links
    """
    links = dict()
    # now verbose mode with bs4 Tags necessary for URL
    for d in get_data('/sys/publinkadmin/', section='right-panel', mode='verbose'):
        link = Link(name=d[0][0], owner=d[1][0], creation=d[3].time['datetime'], count=d[4][0])
        if link.name.startswith('/'):
            link.type = 'directory'
        else:
            link.type = 'file'
        if isinstance(d[5], bs4.element.Tag):
            link.id = d[5].a['data-token'].split('=')[-1]
            link.url = '/'.join((SEAFILE_URL, link.type[0], link.id))
        links[link.id] = link
    return links


def get_groups():
    """
    get groups and their members
    """
    groups = dict()
    result = json.loads(get_ajax('/api/v2.1/admin/groups'))
    for group in result['groups']:
        new_group = Group(name=group['name'],
                          creation=group['created_at'],
                          owner=group['owner'],
                          id=str(group['id']))
        # get members of group
        new_group.members = list()
        result_members = json.loads(get_ajax('/api/v2.1/admin/groups/{0}/members'.format(new_group.id)))
        for member in result_members['members']:
            new_group.members.append(member['name'])
        groups[new_group.id] = new_group
    return groups


def confirm(question):
    """
    return true or false for confirmation of certain destructive tasks
    """
    if FORCE:
        return True
    elif input(question + '? [y/n]: ').lower() in ['y', 'yes']:
        return True
    else:
        return False


# get configuration
try:
    opts, args = getopt.gnu_getopt(sys.argv[1:], 'a:c:u:p:U:Ff', ['admin=',
                                                                  'config=',
                                                                  'username=',
                                                                  'password=',
                                                                  'url=',
                                                                  'start=',
                                                                  'stop=',
                                                                  'force'])
    for opt, arg in opts:
        if opt in ('-a', '--admin'):
            SEAFILE_ADMIN = arg
        if opt in ('-c', '--config'):
            CONFIG_FILE = arg
        if opt in ('-u', '--username'):
            SEAFILE_USERNAME = arg
        if opt in ('-p', '--password'):
            SEAFILE_PASSWORD = arg
        if opt in ('-U', '--url'):
            SEAFILE_URL = arg
        if opt in ('--start'):
            SEAFILE_START = arg
        if opt in ('--stop'):
            SEAFILE_STOP = arg
        if opt in ('-F', '--force'):
            FORCE = True
except getopt.GetoptError:
    error_exit(USAGE)

if not CONFIG_FILE == '':
    if os.path.exists(CONFIG_FILE):
        if not (os.path.isfile(CONFIG_FILE) or
                os.path.islink(CONFIG_FILE)):
            error_exit('Configuration file %s is no file or link.' % CONFIG_FILE)
    else:
        error_exit('Configuration file %s does not exist.' % CONFIG_FILE)

if not CONFIG_FILE == '':
    # instantiate Configparser
    config = configparser.ConfigParser()
    config.read(CONFIG_FILE)
    if config.has_section('seafadm'):
        if config.has_option('seafadm', 'url') and SEAFILE_URL == '':
            SEAFILE_URL = config.get('seafadm', 'url')
        if config.has_option('seafadm', 'username') and SEAFILE_USERNAME == '':
            SEAFILE_USERNAME = config.get('seafadm', 'username')
        if config.has_option('seafadm', 'password') and SEAFILE_PASSWORD == '':
            SEAFILE_PASSWORD = config.get('seafadm', 'password')
        if config.has_option('seafadm', 'admin') and SEAFILE_ADMIN == '':
            SEAFILE_ADMIN = config.get('seafadm', 'admin')
        if config.has_option('seafadm', 'start') and SEAFILE_START == '':
            SEAFILE_START = config.get('seafadm', 'start')
        if config.has_option('seafadm', 'stop') and SEAFILE_STOP == '':
            SEAFILE_STOP = config.get('seafadm', 'stop')
    else:
        error_exit('Section [seafadm] is missing in config file %s.' % CONFIG_FILE)

# set start and stop command to default
if SEAFILE_START == '':
    SEAFILE_START = 'systemctl start seafile'
if SEAFILE_STOP == '':
    SEAFILE_STOP = 'systemctl stop seafile'

# only continue if all needed parameters are configured
if not (SEAFILE_URL != '' and SEAFILE_USERNAME != '' and SEAFILE_PASSWORD != ''):
    error_exit('Something is missing. Please provide URL, username and password of Seafile server.')

# new session with cookies and so on
session = requests.Session()
# do not verify SSL/TLS cerificate
session.verify = False
# extra headers
session.headers.update({'User-Agent': 'Mozilla/5.0', 'Referer': SEAFILE_URL})
# get cookies
session.get(SEAFILE_URL + '/accounts/login/')
# add X-CSRFToken to requests
if 'csrftoken' in session.cookies:  # up to Seafile 6.2
    csrf_token = session.cookies['csrftoken']
elif 'sfcsrftoken' in session.cookies:  # since Seafile 6.3?
    csrf_token = session.cookies['sfcsrftoken']
session.headers.update({'X-CSRFToken': csrf_token})

# get URL parts for form field 'next'
next_url = list()
for i in SEAFILE_URL.split('://')[1].split('/'):
    if len(i) != 0:
        next_url.append(i)
# kick out fqdn
next_url.pop(0)
next_url.extend(('home', 'my'))
next_url = '/' + '/'.join(next_url)

data = {'login': SEAFILE_USERNAME,
        'password': SEAFILE_PASSWORD,
        'csrfmiddlewaretoken': csrf_token,
        'next': next_url,
        'submit': 'Submit',
        'remember_me': 'off'}

# effectively login
session.post(SEAFILE_URL + '/accounts/login/', data)

# check args for seafadm
if len(args) > 0:
    # when only 1 arg is given args is a string no list?
    if args[0].lower() in ['list', 'show']:
        # show everything
        if len(args) >= 2:
            objects = args[1].lower()
            if objects == 'users':
                users = get_users()
                for u in sorted(list(users.values()), key=lambda x: x.mail):
                    print('|'.join((u.mail, str(u.id), u.creation, '%s/%s MB' % (u.used_space, u.quota))))
            elif objects in ['repos', 'libs', 'libraries']:
                libs = get_libaries()
                for l in sorted(list(libs.values()), key=lambda x: (x.owner, x.name)):
                    print('|'.join((l.id, l.owner, l.name)))
            elif objects == 'links':
                links = get_links()
                for l in sorted(list(links.values()), key=lambda x: (x.owner, x.name)):
                    print('|'.join((l.owner, l.creation, l.url, l.count, l.name)))
            elif objects == 'groups':
                groups = get_groups()
                for g in sorted(list(groups.values()), key=lambda x: x.name):
                    print('|'.join((g.name, g.id, g.owner, g.creation, ' '.join(g.members))))
            elif objects == 'user':
                if len(args) >= 3:
                    user = args[2]
                    users = get_users()
                    if user not in users.keys():
                        error_exit('User %s does not exist.' % user)
                    libs = get_libaries()
                    links = get_links()
                    groups = get_groups()
                    users[user].collect_info(libs=libs, links=links, groups=groups)
                    users[user].print_info()
                else:
                    error_exit('User needed to display user info.')
            elif objects == 'group':
                if len(args) >= 3:
                    group = args[2]
                    groups = get_groups()
                    if group not in groups:
                        error_exit('Group %s does not exist.' % group)
                    groups[group].print_info()
                else:
                    error_exit('Group needed to display group info.')
            elif objects == 'all':
                users = get_users()
                libs = get_libaries()
                links = get_links()
                groups = get_groups()
                for u in sorted(list(users.values()), key=lambda x: x.mail):
                    u.collect_info(libs=libs, links=links, groups=groups)
                    u.print_info()
                    print()
            else:
                error_exit(USAGE)
        else:
            error_exit(USAGE)

    elif args[0].lower() == 'delete':
        # user, group, link or repo
        if len(args) >= 3:
            if args[1].lower() in ['user', 'library', 'lib', 'repo', 'link', 'group', 'clean']:
                objects = args[1].lower()
                if objects == 'user':
                    user = args[2]
                    users = get_users()
                    if user in users:
                        if confirm('Delete user %s' % user):
                            user = users[user]
                            get_url('%s/useradmin/remove/%s/' % (SEAFILE_URL, user.mail), {})
                            print('User %s deleted.' % user.mail)
                    else:
                        error_exit('User %s does not exist.' % user)
                elif objects in ['library', 'lib', 'repo']:
                    lib = args[2]
                    libs = get_libaries()
                    if lib in libs:
                        if confirm('Delete library %s' % lib):
                            get_url('%s/sys/seafadmin/delete/%s/' % (SEAFILE_URL, lib), {})
                            print('Library %s deleted.' % lib)
                    else:
                        error_exit('Library %s does not exist.' % lib)
                elif objects == 'link':
                    link = args[2]
                    links = get_links()
                    if link.startswith('http'):
                        # reduce to ID
                        link = link.split('/')[-1]
                    if link in links:
                        if confirm('Delete link %s' % link):
                            get_ajax('/sys/publink/remove/', {'t': link})
                            print('Link %s deleted.' % link)
                    else:
                        error_exit('Link %s does not exist.' % link)
                elif objects == 'group':
                    group = args[2]
                    groups = get_groups()
                    if group in groups:
                        if confirm('Delete group %s' % group):
                            get_url('%s/group/%s/remove/' % (SEAFILE_URL, groups[group].id), {})
                            print('Group %s deleted.' % group)
                    else:
                        error_exit('Group %s does not exist.' % group)
            else:
                error_exit(USAGE)
        else:
            error_exit(USAGE)

    elif args[0].lower() == 'add':
        # link and user
        if len(args) >= 4:
            if args[1].lower() in ['user']:
                email = args[2]
                password = args[3]

                result = get_ajax('/useradmin/add/',
                                  data={'csrfmiddlwaretoken': csrf_token, 'email': email,
                                        'password1': password, 'password2': password},
                                  referer='%s/sys/useradmin/' % SEAFILE_URL)
                result = json.loads(result)
                if 'success' in result:
                    print('Created user %s.' % email)
                elif 'error' in result:
                    try:
                        error = bs4.BeautifulSoup(result['error'], features='lxml').text
                    except:
                        error = bs4.BeautifulSoup(result['error'], features='html.parser').text
                    print(error)
        else:
            error_exit(USAGE)

    elif args[0].lower() == 'quota':
        # domain or user
        if len(args) >= 4:
            if args[1].lower() in ['user', 'domain']:
                objects = args[1].lower()
                if objects == 'user':
                    user = args[2]
                    users = get_users()
                    if user in users:
                        quota = args[3]
                        if confirm('Set quota for user %s to %s MB' % (user, quota)):
                            user = users[user]
                            # check validity of given size
                            try:
                                int(quota)
                            except ValueError:
                                error_exit('%s is no valid quota size.' % quota)
                            print('Set quota for %s to %s MB.' % (user.mail, quota))
                            get_ajax('/useradmin/%s/set_quota/' % user.mail,
                                     data={'email': user.mail, 'space_quota': quota},
                                     referer='%s/useradmin/info/%s/' % (SEAFILE_URL, user.mail))
                    else:
                        error_exit('User %s does not exist.' % user)
                elif objects == 'domain':
                    mode = 'normal'
                    if args[2].lower() == 'not' and len(args) >= 5:
                        domains = args[3:-1]
                        mode = 'reverse'
                    elif args[2].lower() == 'min' and len(args) >= 5:
                        domains = args[3:-1]
                        mode = 'min'
                    else:
                        domains = args[2:-1]
                    quota = args[-1]
                    # check validity of given size
                    try:
                        int(quota)
                    except ValueError:
                        error_exit('%s is no valid quota size.' % quota)
                    users = get_users()
                    users_mod = list()
                    for user in users.values():
                        if mode == 'normal':
                            if user.mail.split('@')[1] in domains:
                                users_mod.append(user)
                        elif mode == 'min':
                            if user.mail.split('@')[1] in domains and int(quota) > int(user.quota):
                                users_mod.append(user)
                        else:
                            if not user.mail.split('@')[1] in domains:
                                users_mod.append(user)
                    if len(users_mod) > 0:
                        question = {'normal': 'Set quota for all users from %s to %s MB' % (', '.join(domains), quota),
                                    'min': 'Set quota for all users from %s to MINIMAL %s MB' % (
                                        ', '.join(domains), quota),
                                    'reverse': 'Set quota for all users NOT from %s to %s MB' % (
                                        ', '.join(domains), quota)}
                        if confirm(question[mode]):
                            for user in users_mod:
                                print('Set quota for %s to %s MB.' % (user.mail, quota))
                                get_ajax('/useradmin/%s/set_quota/' % user.mail,
                                         data={'email': user.mail, 'space_quota': quota},
                                         referer='%s/useradmin/info/%s/' % (SEAFILE_URL, user.mail))
            else:
                error_exit(USAGE)
        else:
            error_exit(USAGE)

    elif args[0].lower() == 'search':
        # search user, link or group
        if len(args) >= 3:
            if args[1].lower() in ['user', 'group', 'link']:
                search = args[2].lower()
                if args[1].lower() == 'user':
                    users = get_users()
                    links = get_links()
                    groups = get_groups()
                    libs = get_libaries()
                    for user in users.values():
                        if search in user.mail.lower():
                            user.collect_info(libs=libs, links=links, groups=groups)
                            user.print_info()

                elif args[1].lower() == 'group':
                    groups = get_groups()
                    for group in groups.values():
                        if search in group.name.lower():
                            group.print_info()
                            print()
                elif args[1].lower() == 'link':
                    links = get_links()
                    for link in links.values():
                        if search in link.name.lower() or \
                                search in link.url:
                            link.print_info()

            else:
                error_exit(USAGE)
        else:
            error_exit(USAGE)

    elif args[0].lower() == 'check':
        # link and user
        if len(args) >= 2:
            if args[1].lower() in ['link', 'links']:
                objects = args[1].lower()
                if objects == 'link' and len(args) >= 2:
                    pass
                    # something is somehow missing?
                if objects == 'links':
                    invalid_links = list()
                    valid_links = list()
                    links = get_links()

                    for l in links.values():
                        if not l.is_valid():
                            invalid_links.append(l)
                        else:
                            valid_links.append(l)
                    for v in sorted(valid_links, key=lambda x: (x.owner, x.name)):
                        print('|'.join(('VALID', v.url, v.owner, v.name)))
                    for i in sorted(invalid_links, key=lambda x: (x.owner, x.name)):
                        print('|'.join(('INVALID', i.url, i.owner, i.name)))
            else:
                error_exit(USAGE)
        else:
            error_exit(USAGE)

    elif args[0].lower() == 'clean':
        # link and user
        if len(args) >= 2:
            if args[1].lower() == 'links':
                objects = args[1].lower()
                if objects == 'links':
                    invalid_links = list()
                    links = get_links()
                    for l in links.values():
                        if not l.is_valid():
                            invalid_links.append(l)
                    for i in invalid_links:
                        print('Deleting invalid link %s|%s|%s.' % (i.url, i.owner, i.name))
                        get_ajax('/sys/publink/remove/', {'t': i.id})
            elif args[1].lower() == 'garbage':
                if len(args) >= 3:
                    try:
                        number_of_threads = int(args[2])
                    except ValueError:
                        error_exit(USAGE)

                if len(args) >= 4:
                    try:
                        SEAFILE_DIR = args[3]
                        if not os.path.exists(SEAFILE_DIR):
                            error_exit('{0} does not exist.'.format(SEAFILE_DIR))
                    except:
                        error_exit(USAGE)

                libraries = get_libaries()
                number_of_libraries = len(libraries)

                print('Stopping seafile')
                # subprocess.call(['systemctl', 'stop', 'seafile'])
                subprocess.call(SEAFILE_STOP.strip().split())

                # just wait some time to let services go down
                time.sleep(10)

                while True:
                    processes = []
                    for p in psutil.process_iter():
                        processes.append(p.name())

                    # only continue if absolutely no component of seafile is running anymore
                    if 'seaf-server' not in processes and \
                       'seafile-controller' not in processes and \
                       'file-server' not in processes and \
                       'ccnet-server' not in processes:
                        print('not running anymore')
                        break
                    else:
                        print('waiting...')
                        time.sleep(1)

                # start worker threads
                for thread in range(number_of_threads):
                    worker = WorkerGarbage(queue_garbage)
                    worker.start()

                # put all libraries in queue to be processed by workers
                for library in libraries.values():
                    queue_garbage.put(library.id)

                # wait until all workers did their work
                queue_garbage.join()
                
                # restart Seafile
                subprocess.call(SEAFILE_START.strip().split())

            else:
                error_exit(USAGE)
        else:
            error_exit(USAGE)

    elif args[0].lower() == 'report':
        # link and user
        if len(args) >= 3:
            if args[1].lower() in ['user']:
                user = args[2]
                users = get_users()
                if user not in users:
                    error_exit('User %s does not exist.' % user)
                libs = get_libaries()
                links = get_links()
                groups = get_groups()
                users[user].collect_info(libs=libs, links=links, groups=groups)
                users[user].print_report()
        else:
            error_exit(USAGE)
else:
    print('\n%s\n' % USAGE)

# log out finally to keep number of open sessions small
get_url(SEAFILE_URL + '/accounts/logout/')
